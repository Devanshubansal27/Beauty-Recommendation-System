{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf184232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting selenium\n",
      "  Downloading selenium-4.26.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in /Applications/anaconda3/lib/python3.12/site-packages (from urllib3[socks]<3,>=1.26->selenium) (2.2.3)\n",
      "Collecting trio~=0.17 (from selenium)\n",
      "  Downloading trio-0.27.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting trio-websocket~=0.9 (from selenium)\n",
      "  Using cached trio_websocket-0.11.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in /Applications/anaconda3/lib/python3.12/site-packages (from selenium) (2024.8.30)\n",
      "Requirement already satisfied: typing_extensions~=4.9 in /Applications/anaconda3/lib/python3.12/site-packages (from selenium) (4.11.0)\n",
      "Requirement already satisfied: websocket-client~=1.8 in /Applications/anaconda3/lib/python3.12/site-packages (from selenium) (1.8.0)\n",
      "Collecting attrs>=23.2.0 (from trio~=0.17->selenium)\n",
      "  Using cached attrs-24.2.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: sortedcontainers in /Applications/anaconda3/lib/python3.12/site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in /Applications/anaconda3/lib/python3.12/site-packages (from trio~=0.17->selenium) (3.7)\n",
      "Collecting outcome (from trio~=0.17->selenium)\n",
      "  Using cached outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in /Applications/anaconda3/lib/python3.12/site-packages (from trio~=0.17->selenium) (1.3.0)\n",
      "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium)\n",
      "  Using cached wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /Applications/anaconda3/lib/python3.12/site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in /Applications/anaconda3/lib/python3.12/site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Downloading selenium-4.26.1-py3-none-any.whl (9.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading trio-0.27.0-py3-none-any.whl (481 kB)\n",
      "Using cached trio_websocket-0.11.1-py3-none-any.whl (17 kB)\n",
      "Using cached attrs-24.2.0-py3-none-any.whl (63 kB)\n",
      "Using cached wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
      "Using cached outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
      "Installing collected packages: wsproto, attrs, outcome, trio, trio-websocket, selenium\n",
      "  Attempting uninstall: attrs\n",
      "    Found existing installation: attrs 23.1.0\n",
      "    Uninstalling attrs-23.1.0:\n",
      "      Successfully uninstalled attrs-23.1.0\n",
      "Successfully installed attrs-24.2.0 outcome-1.3.0.post0 selenium-4.26.1 trio-0.27.0 trio-websocket-0.11.1 wsproto-1.2.0\n"
     ]
    }
   ],
   "source": [
    "! pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6965ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the WebDriver\n",
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62714281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Popup not found or not needed\n",
      "Searching for Face Wash...\n",
      "Scraping page 1 for Face Wash...\n",
      "Scraping page 2 for Face Wash...\n",
      "Scraping page 3 for Face Wash...\n",
      "Scraping page 4 for Face Wash...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 115\u001b[0m\n\u001b[1;32m    112\u001b[0m                 \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;66;03m# Scrape Flipkart data\u001b[39;00m\n\u001b[0;32m--> 115\u001b[0m scrape_flipkart()\n\u001b[1;32m    117\u001b[0m \u001b[38;5;66;03m# Save the data to a DataFrame and export to CSV\u001b[39;00m\n\u001b[1;32m    118\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(data)\n",
      "Cell \u001b[0;32mIn[1], line 109\u001b[0m, in \u001b[0;36mscrape_flipkart\u001b[0;34m()\u001b[0m\n\u001b[1;32m    107\u001b[0m     next_button\u001b[38;5;241m=\u001b[39mdriver\u001b[38;5;241m.\u001b[39mfind_elements(By\u001b[38;5;241m.\u001b[39mXPATH, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m//span[text()=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNext\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    108\u001b[0m     next_button[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mclick()\n\u001b[0;32m--> 109\u001b[0m     sleep(\u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNext button not found on page \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import pandas as pd\n",
    "from time import sleep\n",
    "\n",
    "# Setup options\n",
    "options = Options()\n",
    "options.add_argument(\"--headless\")  # Temporarily disabling headless mode for debugging\n",
    "options.add_argument('--no-sandbox')\n",
    "options.add_argument('--disable-dev-shm-usage')\n",
    "\n",
    "# Initialize WebDriver\n",
    "driver_service = Service(r\"/Users/devanshu29bansalgmail.com/Downloads/chromedriver-mac-arm64/chromedriver\")\n",
    "\n",
    "\n",
    "\n",
    "# Search keywords\n",
    "search_keywords = ['Face Wash', 'Face Scrub', 'moisturizer', 'sunscreen', 'body lotion', \n",
    "                   'Body Wash','face Pack','Dtan Pack' ,'face toner','Face wipes','Face Serum',\"Face Creame\",\"Face Gel\"]\n",
    "#search_keywords=['Skincare Products']\n",
    "platforms = [\"Flipkart\"]\n",
    "\n",
    "# Lists to store scraped data\n",
    "data = []\n",
    "\n",
    "# Function to scrape Flipkart\n",
    "def scrape_flipkart():\n",
    "\n",
    "    for keyword in search_keywords:\n",
    "        driver = webdriver.Chrome(service=driver_service, options=options)\n",
    "        driver.get(\"http://www.flipkart.com\")\n",
    "        sleep(2)\n",
    "    \n",
    "    # Close login popup if present\n",
    "        try:\n",
    "            close_popup = WebDriverWait(driver, 10).until(\n",
    "                EC.element_to_be_clickable((By.XPATH, \"//button[contains(text(),'✕')]\"))\n",
    "            )\n",
    "            close_popup.click()\n",
    "        except Exception:\n",
    "            print(\"Popup not found or not needed\")\n",
    "\n",
    "    \n",
    "        print(f\"Searching for {keyword}...\")\n",
    "        \n",
    "        # Search for the product\n",
    "        try:\n",
    "            search_box = WebDriverWait(driver, 10).until(\n",
    "                EC.presence_of_element_located((By.NAME, \"q\"))\n",
    "            )\n",
    "            search_box.clear()\n",
    "            sleep(5)\n",
    "            search_box.send_keys(keyword)\n",
    "            search_box.submit()\n",
    "            sleep(2)\n",
    "        except Exception as e:\n",
    "            print(f\"Error finding search box: {e}\")\n",
    "            continue\n",
    "\n",
    "        for page in range(1, 35):  # Scrape the first 35 pages\n",
    "            print(f\"Scraping page {page} for {keyword}...\")\n",
    "\n",
    "            try:\n",
    "                # Wait for product elements to load\n",
    "                products = WebDriverWait(driver, 15).until(\n",
    "                    EC.presence_of_all_elements_located((By.XPATH, \"//div[contains(@class, 'slAVV4')]\"))\n",
    "                )\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading products on page {page}: {e}\")\n",
    "                break\n",
    "\n",
    "            for product in products:\n",
    "                try:\n",
    "                    # Update XPath according to current HTML structure\n",
    "                    title = product.find_element(By.XPATH, \".//a[@class='wjcEIp']\").get_attribute(\"title\")\n",
    "                    price = product.find_element(By.XPATH, \".//div[contains(@class, 'Nx9bqj')]\").text\n",
    "                    try: \n",
    "                        rating = product.find_element(By.XPATH, \".//div[contains(@class, 'XQDdHH')]\").text\n",
    "                    except:\n",
    "                        rating = \"N/A\"\n",
    "                        \n",
    "\n",
    "                    brand = title.split()[0]  # Extract brand from title (basic logic)\n",
    "                    product_type = keyword  # Use search keyword as product type\n",
    "                    packing = product.find_element(By.XPATH, \".//div[contains(@class, 'NqpwHC')]\").text\n",
    "\n",
    "                    # Append the scraped data to the list\n",
    "                    data.append({\n",
    "                        \"Product\": title,\n",
    "                        \"Price\": price,\n",
    "                        \"Rating\": rating,\n",
    "                        \"Brand\": brand,\n",
    "                        \"Product Type\": product_type,\n",
    "                        \"Platform\": \"Flipkart\",\n",
    "                        \"Packing\": packing\n",
    "                    })\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Error scraping product: {e}\")\n",
    "\n",
    "            # Go to the next page if available\n",
    "            try:\n",
    "                next_button=driver.find_elements(By.XPATH, \"//span[text()='Next']\")\n",
    "                next_button[0].click()\n",
    "                sleep(10)\n",
    "            except Exception:\n",
    "                print(f\"Next button not found on page {page}\")\n",
    "                break\n",
    "\n",
    "# Scrape Flipkart data\n",
    "scrape_flipkart()\n",
    "\n",
    "# Save the data to a DataFrame and export to CSV\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(\"skincare_producttttts.csv\", index=False)\n",
    "\n",
    "# Close the driver\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502e551e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)\n",
    "df.to_csv(\"skincare_products.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6707aab3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
